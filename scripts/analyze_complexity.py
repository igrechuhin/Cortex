"""Analyze code complexity across the codebase.

Generates a report of functions with high cyclomatic or cognitive
complexity, nesting depth, and other maintainability metrics.

Usage:
    python scripts/analyze_complexity.py

Output:
    - Report of high-complexity functions
    - Nesting depth violations
    - Summary statistics
"""

import ast
from pathlib import Path


def analyze_file(file_path: Path) -> list[dict]:
    """Analyze a single Python file for complexity metrics.

    Args:
        file_path: Path to Python file to analyze

    Returns:
        List of complexity issues found in the file
    """
    results = []

    try:
        with open(file_path) as f:
            tree = ast.parse(f.read(), filename=str(file_path))
    except SyntaxError:
        print(f"âš ï¸  Syntax error in {file_path}, skipping")
        return []

    for node in ast.walk(tree):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
            complexity = calculate_complexity(node)
            nesting = calculate_nesting_depth(node)

            # Report functions with complexity >10 or nesting >3
            if complexity > 10 or nesting > 3:
                # Get relative path from project root
                try:
                    rel_path = file_path.relative_to(Path.cwd())
                except ValueError:
                    rel_path = file_path

                results.append(
                    {
                        "file": str(rel_path),
                        "function": node.name,
                        "line": node.lineno,
                        "complexity": complexity,
                        "nesting": nesting,
                        "issues": _describe_issues(complexity, nesting),
                    }
                )

    return results


def calculate_complexity(node: ast.AST) -> int:
    """Calculate cyclomatic complexity of a function.

    Complexity increases for:
    - Each decision point (if, while, for, with)
    - Each exception handler
    - Each boolean operator (and, or)

    Args:
        node: AST node to analyze

    Returns:
        Cyclomatic complexity score
    """
    complexity = 1  # Base complexity

    for child in ast.walk(node):
        # Decision points
        if isinstance(child, (ast.If, ast.While, ast.For, ast.With)):
            complexity += 1
        # Exception handlers
        elif isinstance(child, ast.ExceptHandler):
            complexity += 1
        # Boolean operators (and, or)
        elif isinstance(child, ast.BoolOp):
            complexity += len(child.values) - 1
        # Comprehensions with conditionals
        elif isinstance(child, (ast.ListComp, ast.SetComp, ast.DictComp)):
            for generator in child.generators:
                complexity += len(generator.ifs)

    return complexity


def calculate_nesting_depth(node: ast.AST, depth: int = 0) -> int:
    """Calculate maximum nesting depth in a function.

    Args:
        node: AST node to analyze
        depth: Current depth level

    Returns:
        Maximum nesting depth found
    """
    max_depth = depth

    for child in ast.iter_child_nodes(node):
        # Control structures that increase nesting
        if isinstance(child, (ast.If, ast.While, ast.For, ast.With, ast.Try)):
            child_depth = calculate_nesting_depth(child, depth + 1)
            max_depth = max(max_depth, child_depth)
        else:
            child_depth = calculate_nesting_depth(child, depth)
            max_depth = max(max_depth, child_depth)

    return max_depth


def _describe_issues(complexity: int, nesting: int) -> list[str]:
    """Generate human-readable issue descriptions.

    Args:
        complexity: Cyclomatic complexity score
        nesting: Maximum nesting depth

    Returns:
        List of issue descriptions
    """
    issues = []

    if complexity > 10:
        issues.append(f"High complexity: {complexity} (target: â‰¤10)")

    if nesting > 3:
        issues.append(f"Deep nesting: {nesting} levels (target: â‰¤3)")

    return issues


def main():
    """Run complexity analysis on all source files."""
    src_path = Path("src/cortex")

    if not src_path.exists():
        print(f"âŒ Source directory not found: {src_path}")
        return 1

    print("ğŸ” Analyzing code complexity...\n")

    all_results = []
    file_count = 0

    for py_file in sorted(src_path.rglob("*.py")):
        if "__pycache__" in str(py_file) or py_file.name.startswith("test_"):
            continue

        file_count += 1
        results = analyze_file(py_file)
        all_results.extend(results)

    # Sort by complexity (highest first), then by nesting
    all_results.sort(key=lambda x: (x["complexity"], x["nesting"]), reverse=True)

    # Print results
    print("=" * 80)
    print("COMPLEXITY ANALYSIS REPORT")
    print("=" * 80)

    if not all_results:
        print("\nâœ… No complexity issues found!")
        print(f"\nğŸ“Š Analyzed {file_count} files")
        return 0

    # Group by severity
    high_complexity = [r for r in all_results if r["complexity"] > 15]
    medium_complexity = [r for r in all_results if 10 < r["complexity"] <= 15]
    deep_nesting = [r for r in all_results if r["nesting"] > 3]

    # Print high complexity functions
    if high_complexity:
        print(f"\nğŸ”´ HIGH COMPLEXITY (>{15}):")
        print("-" * 80)
        for result in high_complexity:
            print(f"\nğŸ“ {result['file']}:{result['line']}")
            print(f"   Function: {result['function']}")
            print(
                f"   Complexity: {result['complexity']} (nesting: {result['nesting']})"
            )
            for issue in result["issues"]:
                print(f"   - {issue}")

    # Print medium complexity functions
    if medium_complexity:
        print(f"\nğŸŸ¡ MEDIUM COMPLEXITY (11-15):")
        print("-" * 80)
        for result in medium_complexity:
            print(f"\nğŸ“ {result['file']}:{result['line']}")
            print(f"   Function: {result['function']}")
            print(
                f"   Complexity: {result['complexity']} (nesting: {result['nesting']})"
            )

    # Print deep nesting issues
    nesting_only = [r for r in deep_nesting if r["complexity"] <= 10]
    if nesting_only:
        print(f"\nğŸŸ  DEEP NESTING (>3 levels):")
        print("-" * 80)
        for result in nesting_only:
            print(f"\nğŸ“ {result['file']}:{result['line']}")
            print(f"   Function: {result['function']}")
            print(
                f"   Nesting: {result['nesting']} levels (complexity: {result['complexity']})"
            )

    # Summary statistics
    print("\n" + "=" * 80)
    print("SUMMARY")
    print("=" * 80)
    print(f"\nğŸ“Š Total files analyzed: {file_count}")
    print(f"ğŸ”´ High complexity functions (>15): {len(high_complexity)}")
    print(f"ğŸŸ¡ Medium complexity functions (11-15): {len(medium_complexity)}")
    print(f"ğŸŸ  Deep nesting functions (>3 levels): {len(nesting_only)}")
    print(f"ğŸ“ˆ Total issues: {len(all_results)}")

    if all_results:
        avg_complexity = sum(r["complexity"] for r in all_results) / len(all_results)
        max_complexity = max(r["complexity"] for r in all_results)
        print(f"\nğŸ“Š Average complexity (issues only): {avg_complexity:.1f}")
        print(f"ğŸ“Š Maximum complexity: {max_complexity}")

    print("\n" + "=" * 80)
    print("RECOMMENDATIONS")
    print("=" * 80)
    print(
        """
1. Apply guard clauses to reduce nesting
2. Extract complex conditionals to named functions
3. Use strategy pattern for switch-like if-elif chains
4. Extract nested loops to separate methods
5. Use list comprehensions for simple iterations
"""
    )

    return 0


if __name__ == "__main__":
    exit(main())
